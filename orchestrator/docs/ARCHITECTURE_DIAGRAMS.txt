â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    LANGGRAPH TUTORING ARCHITECTURE DIAGRAM                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRY POINT                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                     â”‚
â”‚                        Student Input (question, CLI history)                        â”‚
â”‚                                  â†“                                                 â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                        â”‚  intent_router_node  â”‚  â† HEURISTIC-BASED ROUTING         â”‚
â”‚                        â”‚  (keyword analysis)  â”‚    (not LLM)                       â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                   â†“                                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                    â”‚ Classified Intent:       â”‚                                   â”‚
â”‚                    â”‚ - teaching               â”‚                                   â”‚
â”‚                    â”‚ - troubleshooting        â”‚                                   â”‚
â”‚                    â”‚ - ambiguous              â”‚                                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚      â”‚      â”‚
                â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•©â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                â•‘  CONDITIONAL ROUTING (LangGraph Edges)  â•‘
                â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â”‚      â”‚      â”‚
                    Teaching  â”‚      â”‚      â”‚  Troubleshooting
                              â†“      â†“      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEACHING PATH       â”‚    â”‚   â”‚ TROUBLESHOOTING PATH â”‚
        â”‚  (Conceptual)        â”‚    â”‚   â”‚ (Errors)             â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                      â”‚    â”‚   â”‚                      â”‚
        â”‚ 1. teaching_         â”‚    â”‚   â”‚ 1. retrieval_node    â”‚
        â”‚    retrieval_node    â”‚    â”‚   â”‚    (Query enhance)   â”‚
        â”‚    - k=3 docs        â”‚    â”‚   â”‚    - k=12 results    â”‚
        â”‚    - Concept focus   â”‚    â”‚   â”‚    - Error priority  â”‚
        â”‚                      â”‚    â”‚   â”‚                      â”‚
        â”‚ 2. teaching_         â”‚    â”‚   â”‚ 2. feedback_node     â”‚
        â”‚    feedback_node     â”‚    â”‚   â”‚    (Complex)         â”‚
        â”‚    - Conceptual      â”‚    â”‚   â”‚    - Error detect    â”‚
        â”‚    - 2-4 sentences   â”‚    â”‚   â”‚    - Tool calling    â”‚
        â”‚    - Educational     â”‚    â”‚   â”‚    - Reasoning mode  â”‚
        â”‚                      â”‚    â”‚   â”‚    - 5-15s           â”‚
        â”‚ 3. END               â”‚    â”‚   â”‚                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚ 3. paraphrasing_node â”‚
        Returns: 2-5s latency       â”‚   â”‚    - Cleanup         â”‚
                                    â”‚   â”‚    - Remove cruft    â”‚
                                    â”‚   â”‚    - 1-3s            â”‚
                                    â”‚   â”‚                      â”‚
                                    â”‚   â”‚ 4. END               â”‚
                                    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚   Returns: 5-15s latency
                            (Default for
                            Ambiguous)
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                       â”‚
        â–¼                                                       â–¼
    TEACHING PATH RESULT                        TROUBLESHOOTING PATH RESULT
    - Clear explanation                        - Error diagnosed
    - Conceptual depth                         - Fix provided
    - No CLI procedures                        - Tool results if used


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           STATE FLOW THROUGH SYSTEM                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TutoringState (40+ fields)
â”œâ”€ Student Interaction: question, conversation_history
â”œâ”€ Lab Context: current_lab, lab_title, lab_objectives, lab_instructions
â”œâ”€ CLI Context: cli_history (CRITICAL), current_device_id, simulator_devices
â”œâ”€ RAG Output: retrieved_docs, retrieval_query
â”œâ”€ Routing: intent (teaching|troubleshooting|ambiguous), tutoring_strategy
â”œâ”€ Output: feedback_message
â””â”€ Progress: mastery_level, success_rate, concepts_understood

Flow Example (Troubleshooting Path):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
State IN: {student_question, cli_history=[5 commands with errors]}
    â†“
    intent_router processes error keywords
    â†“
    intent = "troubleshooting"
    â†“
    retrieval_node: processes cli_history, detects error patterns
    â”œâ”€ Extracts command keywords from errors
    â”œâ”€ Prioritizes error_pattern docs from FAISS
    â””â”€ Updates: retrieved_docs, retrieval_query
    â†“
    feedback_node: Complex processing
    â”œâ”€ Builds CLI context (with error detection)
    â”œâ”€ Injects error_type, diagnosis, fix inline
    â”œâ”€ Adds RAG docs to system prompt
    â”œâ”€ Enables tool calling (if no CLI errors)
    â”œâ”€ LLM generates response with reasoning
    â””â”€ Updates: feedback_message, conversation_history
    â†“
    paraphrasing_node: Cleanup
    â”œâ”€ Removes preambles
    â”œâ”€ Removes internal error codes
    â””â”€ Returns clean feedback_message
    â†“
State OUT: {feedback_message, conversation_history, total_interactions+1}


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      ERROR DETECTION INTEGRATION                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CLI Command: "hostnane Router1"
Router Output: "Invalid input detected at '^' marker" + "% Invalid input..."
                ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~

Detection Pipeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Signature Check
   âœ“ "Invalid input" in output â†’ YES
   âœ“ "Incomplete command" in output â†’ NO

2. Pattern Regex Match
   âœ“ Command matches pattern regex â†’ YES

3. Fuzzy Matching
   â”œâ”€ Extract word at ^ marker â†’ "hostnane"
   â”œâ”€ Detect Cisco mode from output â†’ "global_config"
   â”œâ”€ Find similar command â†’ "hostname" (similarity: 0.875)
   â””â”€ Return typo info

4. Return DetectionResult
   â”œâ”€ error_type: "TYPO_IN_COMMAND"
   â”œâ”€ diagnosis: "You have a typo: 'hostnane' â†’ 'hostname'"
   â”œâ”€ fix: "hostname Router1"
   â””â”€ metadata: {pattern_id, similarity: 0.875, typo_word: "hostnane"}

Implementation in feedback_node:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if error_detected:
    cli_context += f"âš ï¸ ERROR TYPE: {result.error_type}\n"
    cli_context += f"ğŸ“‹ DIAGNOSIS: {result.diagnosis}\n"
    cli_context += f"âœ… FIX: {result.fix}\n"

LLM receives these in system prompt and generates response:
"You have a typo in the command. You wrote 'hostnane' but the correct command
is 'hostname Router1'. Try that and let me know if it works!"


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      TOOL CALLING INTEGRATION                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Tool: get_device_running_config(device_name: str) â†’ str

When Called:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Student asks: "What IP is configured on Router1?"
- CLI history doesn't show the config
- Tool decision: ENABLED (no CLI errors visible)
- LLM calls: get_device_running_config("Router1")

Iteration Logic:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Call 1: LLM (with tools)
  â†’ "I should check the running config"
  â†’ Returns tool_call

Execute: get_device_running_config("Router1")
  â†’ Returns: "interface GigabitEthernet0/0\n ip address 192.168.1.1 255.255.255.0..."

Call 2: LLM (with tool result)
  â†’ "Based on the running configuration, I can see..."
  â†’ Returns final response

When DISABLED:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- CLI errors are present (e.g., "Invalid input" messages)
- Tool disabled to avoid: extra latency + potential hallucination
- Feedback generated from: CLI context + retrieved docs (sufficient for error cases)

Max Iterations: 3
Timeout: Per tool call ~500ms, overall ~5-10s


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      RAG SMART PRIORITIZATION                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FAISS Retrieval (k=12):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Results: [Error Pattern, Command Ref, Lab Context, ...]

Categorization:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Error Pattern Chunks (cisco-ios-error-patterns.md)
â”‚  â””â”€ "Invalid input errors", "CIDR notation", "Mode errors"
â”œâ”€ Command Reference (cisco-ios-command-reference.md)  
â”‚  â””â”€ "hostname syntax", "ip address format"
â””â”€ Lab Specific (current lab docs)
   â””â”€ "Lab topology", "devices in this lab"

Priority Logic:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if has_error_marker (^) or error_keywords:
    # ERROR PATH
    docs = error_patterns[:2] + command_ref[:2] + lab_specific[:1]
    (4-5 documents focused on fixing the error)
else:
    # STANDARD PATH  
    docs = command_ref[:3] + lab_specific[:2]
    (4-5 documents for general learning)

Result: LLM receives most relevant docs first, focused on the student's actual problem


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      STREAMING RESPONSE FLOW                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User calls: tutor.ask_stream(question)

Phase 1: Prepare Context (non-streaming)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Build CLI context with inline error detection
â”œâ”€ Build diagnosis context from preprocessed results
â”œâ”€ Run FAISS retrieval with error prioritization
â”œâ”€ Call LLM once to check: "Do you need tools?"
â””â”€ Time: ~2-3 seconds

Phase 2: Execute Tools (if needed)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ If LLM wants tools:
â”‚  â”œâ”€ Yield: {"type": "info", "message": "Retrieving config..."}
â”‚  â”œâ”€ Execute each tool call
â”‚  â””â”€ Add results to message history
â””â”€ Time: ~500ms-2s per tool

Phase 3: Stream Response
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Call LLM with stream=True
â”œâ”€ For each chunk:
â”‚  â”œâ”€ Filter out <TOOLCALL> and <THINKING> tags
â”‚  â”œâ”€ Yield: {"type": "content", "text": chunk}
â”‚  â””â”€ User sees it immediately
â””â”€ Time: ~1-3s for response start, ~5-15s total

Phase 4: Final Metadata
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Yield: {"type": "metadata", "progress": {...}, "hints": ...}
â””â”€ Time: instant

Total Latency: 2-3s to first visible content, 8-20s total


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      NODE COMPLEXITY COMPARISON                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEACHING PATH:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
teaching_retrieval_node:
  Input: student_question, current_lab
  Processing: Simple query expansion + FAISS search (k=3)
  Output: retrieved_docs
  Complexity: LOW
  Time: 200-500ms

teaching_feedback_node:
  Input: student_question, retrieved_docs, mastery_level
  Processing: Build context + LLM call (temp=0.7, max_tokens=400)
  Output: feedback_message
  Complexity: LOW
  Time: 2-5s
  
  â†’ Teaching path is lightweight, educational, quick

TROUBLESHOOTING PATH:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
retrieval_node:
  Input: student_question, current_lab, cli_history
  Processing: Error analysis + enhanced query + FAISS (k=12) + prioritization
  Output: retrieved_docs
  Complexity: MEDIUM
  Time: 300-700ms

feedback_node:
  Input: 10+ state fields (question, docs, cli_history, etc.)
  Processing: 
    - CLI context building with error detection (CRITICAL)
    - Preprocessed diagnosis context injection
    - RAG doc context building
    - Complex system prompt assembly
    - Tool availability decision logic
    - LLM iteration loop (max 3 calls)
    - Tool execution and result injection
  Output: feedback_message, updated conversation_history
  Complexity: VERY HIGH
  Time: 5-15s
  
paraphrasing_node:
  Input: feedback_message
  Processing: LLM cleanup (temp=0.1, max_tokens=500)
  Output: cleaned feedback_message
  Complexity: LOW
  Time: 1-3s
  
  â†’ Troubleshooting path is heavyweight but comprehensive

